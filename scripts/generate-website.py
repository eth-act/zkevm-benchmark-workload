#!/usr/bin/env python3
"""
Generate a website displaying zkEVM benchmark metrics.

This script processes zkevm-metrics files generated by the stateless-validator
integration tests and creates an HTML website showing cycle counts and execution
times per zkVM and EL combination.
"""

import argparse
import json
import re
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# Import the human-readable display name function
from test_name_parser import get_display_name

@dataclass
class MetricsFile:
    """Represents a single metrics file with its metadata."""
    name: str
    metrics: Dict[str, Any]
    zkvm: str
    version: str
    file_path: str
    el: str = 'unknown'


@dataclass
class TestResult:
    """Represents aggregated test results for a zkVM/EL combination."""
    test_count: int = 0
    successful_tests: int = 0
    crashed_tests: int = 0
    success_percentage: float = 0.0
    total_cycles_min: Optional[int] = None
    total_cycles_max: Optional[int] = None
    total_cycles_avg: Optional[float] = None
    total_cycles_sum: Optional[int] = None
    execution_time_min: Optional[float] = None
    execution_time_max: Optional[float] = None
    execution_time_avg: Optional[float] = None
    execution_time_sum: Optional[float] = None


@dataclass
class ZkVMMetrics:
    """Container for metrics organized by zkVM and EL."""
    data: Dict[str, Dict[str, List[MetricsFile]]] = field(default_factory=dict)

    def add_metrics(self, zkvm_with_version: str, el: str, metrics_file: MetricsFile) -> None:
        """Add a metrics file to the collection."""
        if zkvm_with_version not in self.data:
            self.data[zkvm_with_version] = {}
        if el not in self.data[zkvm_with_version]:
            self.data[zkvm_with_version][el] = []
        self.data[zkvm_with_version][el].append(metrics_file)


def find_metrics_directories(base_path: Path) -> List[Path]:
    """Find all directories containing zkevm-metrics data."""
    return sorted(
        item for item in base_path.iterdir()
        if item.is_dir() and item.name.startswith('zkevm-metrics')
    )

def parse_metrics_file(file_path: Path) -> Optional[Dict[str, Any]]:
    """Parse a single metrics JSON file."""
    try:
        with open(file_path, 'r') as f:
            return json.load(f)
    except (json.JSONDecodeError, FileNotFoundError) as e:
        print(f"Warning: Could not parse {file_path}: {e}")
        return None

def extract_zkvm_and_variant(metrics_dir: Path) -> Tuple[Optional[str], Optional[str]]:
    """Extract zkVM and variant information from directory structure or file names."""
    dir_name = metrics_dir.name

    if dir_name == 'zkevm-metrics':
        # Look for subdirectories with zkvm-version pattern
        subdirs = [d for d in metrics_dir.iterdir() if d.is_dir()]
        if subdirs:
            subdir = subdirs[0]  # Take the first one
            match = re.match(r'([^-]+)-(.+)', subdir.name)
            if match:
                return match.group(1), match.group(2)
    else:
        # Pattern: zkevm-metrics-{zkvm}-{variant}
        match = re.match(r'zkevm-metrics-([^-]+)-(.+)', dir_name)
        if match:
            return match.group(1), match.group(2)

    return None, None

def process_metrics_file(
    json_file: Path,
    zkvm: str,
    version: str,
    zkvm_with_version: str,
    el: Optional[str] = None
) -> Optional[MetricsFile]:
    """Process a single metrics JSON file and return a MetricsFile object."""
    if json_file.name == 'hardware.json':
        return None

    metrics = parse_metrics_file(json_file)
    if metrics is None:
        return None

    test_name = metrics.get('name', json_file.stem)

    return MetricsFile(
        name=test_name,
        metrics=metrics,
        zkvm=zkvm,
        version=version,
        file_path=str(json_file),
        el=el
    )


def process_metrics_directory(metrics_dir: Path, zkvm_metrics: ZkVMMetrics) -> None:
    """Process a single metrics directory and add to zkvm_metrics."""
    if metrics_dir.name == 'zkevm-metrics':
        for el_dir in metrics_dir.iterdir():
            if el_dir.is_dir() and el_dir.name != 'hardware.json':
                el_name = el_dir.name  

                # Process each zkVM subdirectory within the EL folder
                for zkvm_dir in el_dir.iterdir():
                    if zkvm_dir.is_dir():
                        match = re.match(r'([^-]+)-(.+)', zkvm_dir.name)
                        if match:
                            zkvm = match.group(1)
                            version = match.group(2)
                            zkvm_with_version = f"{zkvm} ({version})"

                            for json_file in zkvm_dir.glob('*.json'):
                                metrics_file = process_metrics_file(
                                    json_file, zkvm, version, zkvm_with_version, el_name
                                )
                                if metrics_file:
                                    zkvm_metrics.add_metrics(
                                        zkvm_with_version, el_name, metrics_file
                                    )
    else:
        # Process other zkevm-metrics-* directories
        zkvm, variant = extract_zkvm_and_variant(metrics_dir)
        if zkvm is None:
            return

        zkvm_with_version = f"{zkvm} ({variant})" if variant else zkvm

        for json_file in metrics_dir.glob('*.json'):
            metrics_file = process_metrics_file(
                json_file, zkvm, variant or '', zkvm_with_version
            )
            if metrics_file:
                zkvm_metrics.add_metrics(
                    zkvm_with_version, metrics_file.el, metrics_file
                )


def collect_metrics_data(base_path: Path) -> Dict[str, Dict[str, List[MetricsFile]]]:
    """
    Collect all metrics data organized by zkVM and EL combination.

    Returns:
        Dict with structure: {zkvm_with_version: {el: [metrics_data]}}
    """
    zkvm_metrics = ZkVMMetrics()
    metrics_dirs = find_metrics_directories(base_path)

    for metrics_dir in metrics_dirs:
        process_metrics_directory(metrics_dir, zkvm_metrics)

    return zkvm_metrics.data

def calculate_summary_stats(test_data: List[MetricsFile]) -> TestResult:
    """Calculate summary statistics for a list of test results."""
    if not test_data:
        return TestResult()

    cycle_counts: List[int] = []
    execution_times: List[float] = []
    successful_tests = 0
    crashed_tests = 0
    total_tests = len(test_data)

    for test in test_data:
        metrics = test.metrics
        execution = metrics.get('execution', {})

        if 'success' in execution:
            successful_tests += 1
            success_data = execution['success']

            # Extract cycle count
            total_cycles = success_data.get('total_num_cycles')
            if total_cycles:
                cycle_counts.append(total_cycles)

            # Extract execution time (convert to seconds)
            duration = success_data.get('execution_duration', {})
            if 'secs' in duration and 'nanos' in duration:
                total_seconds = duration['secs'] + duration['nanos'] / 1_000_000_000
                execution_times.append(total_seconds)
        else:
            # Count as crashed if not successful
            crashed_tests += 1

    result = TestResult(
        test_count=total_tests,
        successful_tests=successful_tests,
        crashed_tests=crashed_tests,
        success_percentage=(successful_tests / total_tests * 100) if total_tests > 0 else 0
    )

    if cycle_counts:
        result.total_cycles_min = min(cycle_counts)
        result.total_cycles_max = max(cycle_counts)
        result.total_cycles_avg = sum(cycle_counts) / len(cycle_counts)
        result.total_cycles_sum = sum(cycle_counts)

    if execution_times:
        result.execution_time_min = min(execution_times)
        result.execution_time_max = max(execution_times)
        result.execution_time_avg = sum(execution_times) / len(execution_times)
        result.execution_time_sum = sum(execution_times)

    return result

def format_number(num: float, precision: int = 2) -> str:
    """Format a number with thousands separators."""
    if isinstance(num, int) or num.is_integer():
        return f"{int(num):,}"
    else:
        return f"{num:,.{precision}f}"

def format_time(seconds: float) -> str:
    """Format time duration in a human-readable format."""
    if seconds < 1:
        return f"{seconds * 1000:.1f}ms"
    elif seconds < 60:
        return f"{seconds:.2f}s"
    elif seconds < 3600:
        minutes = seconds / 60
        return f"{minutes:.1f}m"
    else:
        hours = seconds / 3600
        return f"{hours:.1f}h"

def get_html_template() -> str:
    """Return the HTML template for the report."""
    return '''<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>zkEVM Benchmark Results</title>
    <style>
        {css_styles}
    </style>
    <script>
        {javascript_code}
    </script>
</head>
<body>
    <div class="container">
        <h1>zkEVM Stateless Validator Benchmark Results</h1>
        {content}
        <div class="timestamp">
            <p>Generated on {timestamp}</p>
        </div>
    </div>
</body>
</html>
'''


def get_css_styles() -> str:
    """Return the CSS styles for the report."""
    return '''
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            line-height: 1.6;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #333;
            margin-top: 0;
        }
        h1 {
            text-align: center;
            border-bottom: 3px solid #007acc;
            padding-bottom: 10px;
        }
        .summary-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: white;
            font-size: 0.9em;
        }
        .summary-table th,
        .summary-table td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        .summary-table th {
            background-color: #007acc;
            color: white;
            font-weight: bold;
            position: sticky;
            top: 0;
            z-index: 10;
        }
        .summary-table tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .summary-table tr:hover {
            background-color: #f0f8ff;
        }
        .results-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: white;
            font-size: 0.85em;
        }
        .results-table th,
        .results-table td {
            border: 1px solid #ddd;
            padding: 6px;
            text-align: center;
        }
        .results-table th {
            background-color: #007acc;
            color: white;
            font-weight: bold;
            position: sticky;
            top: 0;
            z-index: 10;
        }
        .results-table th.test-name {
            text-align: left;
            min-width: 200px;
        }
        .results-table tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .results-table tr:hover {
            background-color: #f0f8ff;
        }
        .test-name-cell {
            text-align: left !important;
            font-weight: bold;
            max-width: 300px;
            word-wrap: break-word;
        }
        .metric-value {
            font-weight: bold;
            color: #2e7d32;
        }
        .neutral-value {
            font-weight: bold;
            color: #333;
        }
        .cycles-value {
            color: #1976d2;
            font-family: monospace;
        }
        .time-value {
            color: #388e3c;
            font-family: monospace;
        }
        .error-value {
            color: #d32f2f;
            font-style: italic;
        }
        .no-data {
            color: #999;
            font-style: italic;
        }
        .timestamp {
            text-align: center;
            color: #666;
            font-style: italic;
            margin: 15px 0 25px;
        }
        .section-title {
            color: #007acc;
            font-size: 1.3em;
            margin: 30px 0 15px 0;
            border-bottom: 2px solid #007acc;
            padding-bottom: 5px;
        }
        .overflow-container {
            overflow-x: auto;
            margin: 20px 0;
        }
        .combined-cell {
            display: flex;
            flex-direction: column;
            gap: 2px;
        }
        .sortable {
            cursor: pointer;
            user-select: none;
            position: relative;
        }
        .sortable:hover {
            background-color: #0056b3 !important;
        }
        .sort-indicator {
            font-size: 0.8em;
            margin-left: 5px;
            opacity: 0.7;
        }
        .sort-asc::after {
            content: ' ‚Üë';
        }
        .sort-desc::after {
            content: ' ‚Üì';
        }
        .el-section {
            margin: 20px 0;
            border: 1px solid #ddd;
            border-radius: 8px;
            overflow: hidden;
        }
        .el-header {
            background-color: #f8f9fa;
            padding: 15px 20px;
            margin: 0;
            border-bottom: 1px solid #ddd;
            color: #007acc;
            font-size: 1.2em;
            font-weight: bold;
        }
        .el-header:hover {
            background-color: #e9ecef;
        }
        .el-content {
            padding: 0;
            transition: max-height 0.3s ease-out;
            overflow: hidden;
        }
        .el-content.collapsed {
            max-height: 0;
        }
        .toggle-indicator {
            float: right;
            transition: transform 0.3s ease;
        }
        .toggle-indicator.rotated {
            transform: rotate(-90deg);
        }
    '''


def get_javascript_code() -> str:
    """Return the JavaScript code for the report."""
    return '''
        let currentSort = { column: -1, direction: 'desc' }; // Default to desc for average column
        let elSorts = {}; // Track sort state for each EL section

        function toggleSection(el) {
            const content = document.getElementById(`section-${el}`);
            const indicator = document.getElementById(`toggle-${el}`);

            if (content.classList.contains('collapsed')) {
                content.classList.remove('collapsed');
                indicator.classList.remove('rotated');
                indicator.textContent = '‚ñº';
            } else {
                content.classList.add('collapsed');
                indicator.classList.add('rotated');
                indicator.textContent = '‚ñ∂';
            }
        }

        function extractNumericValue(cellContent, isAverageColumn = false) {
            if (isAverageColumn) {
                // For average column, use the data-avg-time attribute
                const cell = cellContent.closest ? cellContent : document.createElement('div');
                if (typeof cellContent === 'string') {
                    cell.innerHTML = cellContent;
                }
                const avgTimeAttr = cell.querySelector('[data-avg-time]');
                if (avgTimeAttr) {
                    const avgTime = parseFloat(avgTimeAttr.getAttribute('data-avg-time'));
                    return avgTime >= 0 ? avgTime : -1; // -1 for no data
                }
                return -1;
            }

            // Extract cycles from the cell content
            const cyclesMatch = cellContent.match(/([0-9,]+)\s+cycles/);
            if (cyclesMatch) {
                return parseInt(cyclesMatch[1].replace(/,/g, ''));
            }

            // If it's a failed/error/no-data cell, return appropriate values for sorting
            if (cellContent.includes('Failed') || cellContent.includes('Error')) {
                return -1; // Special value for failed tests
            }
            if (cellContent.includes('No cycle data') || cellContent.includes('-')) {
                return -2; // Special value for missing data
            }

            return -3; // Default for other cases
        }

        function sortElTable(el, columnIndex) {
            const table = document.querySelector(`#tbody-${el}`);
            const rows = Array.from(table.querySelectorAll('tr'));
            const headers = document.querySelectorAll(`#section-${el} .sortable`);
            const isAverageColumn = columnIndex === headers.length - 1; // Last column is average

            // Initialize sort state for this EL if not exists
            if (!elSorts[el]) {
                elSorts[el] = { column: -1, direction: 'asc' };
            }

            // Determine sort direction
            if (elSorts[el].column === columnIndex) {
                elSorts[el].direction = elSorts[el].direction === 'asc' ? 'desc' : 'asc';
            } else {
                elSorts[el].column = columnIndex;
                elSorts[el].direction = 'asc';
            }

            // Update sort indicators for this EL section
            headers.forEach(th => {
                th.classList.remove('sort-asc', 'sort-desc');
            });

            const currentHeader = headers[columnIndex];
            currentHeader.classList.add(elSorts[el].direction === 'asc' ? 'sort-asc' : 'sort-desc');

            // Sort rows
            rows.sort((a, b) => {
                const cellIndexInRow = isAverageColumn ? a.cells.length - 1 : columnIndex + 1; // +1 because first column is test name
                const cellA = a.cells[cellIndexInRow];
                const cellB = b.cells[cellIndexInRow];

                let valueA, valueB;

                if (isAverageColumn) {
                    // For average column, extract from data-avg-time attribute
                    const attrA = cellA.getAttribute('data-avg-time');
                    const attrB = cellB.getAttribute('data-avg-time');
                    valueA = attrA ? parseFloat(attrA) : -1;
                    valueB = attrB ? parseFloat(attrB) : -1;
                } else {
                    // For other columns, extract cycles from content
                    valueA = extractNumericValue(cellA.innerHTML);
                    valueB = extractNumericValue(cellB.innerHTML);
                }

                let comparison = 0;

                if (elSorts[el].direction === 'desc') {
                    // For descending, put Failed (-1) at the top for cycle columns, but bottom for average
                    if (!isAverageColumn) {
                        if (valueA === -1 && valueB !== -1) return -1;
                        if (valueA !== -1 && valueB === -1) return 1;
                        if (valueA === -1 && valueB === -1) return 0;
                    }

                    // For missing data, put at bottom
                    if (valueA < 0 && valueB >= 0) return 1;
                    if (valueA >= 0 && valueB < 0) return -1;
                    if (valueA < 0 && valueB < 0) return valueA - valueB;

                    comparison = valueB - valueA; // Descending for numeric values
                } else {
                    // For ascending, put Failed and missing data at bottom
                    if ((valueA < 0) && (valueB >= 0)) return 1;
                    if ((valueA >= 0) && (valueB < 0)) return -1;
                    if ((valueA < 0) && (valueB < 0)) return valueA - valueB; // Sort negative values

                    comparison = valueA - valueB; // Ascending for numeric values
                }

                return comparison;
            });

            // Re-append sorted rows
            rows.forEach(row => table.appendChild(row));
        }

        function initializeSorting() {
            // Add event listeners to all sortable headers
            const sortableHeaders = document.querySelectorAll('.sortable[data-el][data-col]');
            sortableHeaders.forEach(header => {
                header.addEventListener('click', function() {
                    const el = this.getAttribute('data-el');
                    const col = parseInt(this.getAttribute('data-col'));
                    sortElTable(el, col);
                });
            });

            // Get all EL sections and sort each by average execution time column by default
            const elSections = document.querySelectorAll('[id^="section-"]');
            elSections.forEach(section => {
                const el = section.id.replace('section-', '');
                const headers = section.querySelectorAll('.sortable');

                if (headers.length > 0) {
                    const avgColumnIndex = headers.length - 1; // Last column is average
                    elSorts[el] = { column: avgColumnIndex, direction: 'asc' }; // Will be toggled to desc
                    sortElTable(el, avgColumnIndex);
                }
            });
        }

        // Initialize when DOM is loaded
        document.addEventListener('DOMContentLoaded', initializeSorting);
    '''


def generate_summary_table(metrics_data: Dict[str, Dict[str, List[MetricsFile]]]) -> str:
    """Generate the summary table HTML."""
    if not metrics_data:
        return '''
        <div class="no-data">
            <h2>No metrics data found</h2>
            <p>No benchmark results were found in the specified directories.</p>
        </div>
        '''

    html = '''
        <h2 class="section-title">üìä Summary by zkVM and EL</h2>
        <div class="overflow-container">
        <table class="summary-table">
            <thead>
                <tr>
                    <th>EL</th>
                    <th>zkVM</th>
                    <th>Successful</th>
                    <th>Crashed</th>
                    <th>Total</th>
                    <th>Success %</th>
                </tr>
            </thead>
            <tbody>
    '''

    summary_rows = []
    for zkvm, el_data in metrics_data.items():
        for el, test_data in el_data.items():
            stats = calculate_summary_stats(test_data)
            summary_rows.append((el, zkvm, stats))

    for el, zkvm, stats in sorted(summary_rows, key=lambda item: (item[0].lower(), item[1].lower())):
        html += f'''
                <tr>
                    <td>{el}</td>
                    <td><strong>{zkvm}</strong></td>
                    <td class="neutral-value">{stats.successful_tests}</td>
                    <td class="error-value">{stats.crashed_tests}</td>
                    <td class="neutral-value">{stats.test_count}</td>
                    <td class="metric-value">{stats.success_percentage:.1f}%</td>
                </tr>'''

    html += '''
            </tbody>
        </table>
        </div>
    '''
    return html


def generate_test_cell(
    test_result: Optional[MetricsFile],
    cycle_counts: List[int],
    execution_times: List[float]
) -> Tuple[str, Optional[int], Optional[float]]:
    """Generate HTML content for a test result cell."""
    if test_result:
        metrics = test_result.metrics
        execution = metrics.get('execution', {})

        if 'success' in execution:
            success_data = execution['success']
            cycles = success_data.get('total_num_cycles')
            duration = success_data.get('execution_duration', {})

            cell_content = '<div class="combined-cell">'

            if cycles:
                cycles_formatted = format_number(cycles)
                cell_content += f'<span class="cycles-value">{cycles_formatted} cycles</span>'
                cycle_counts.append(cycles)
            else:
                cell_content += '<span class="no-data">No cycle data</span>'

            if 'secs' in duration and 'nanos' in duration:
                total_seconds = duration['secs'] + duration['nanos'] / 1_000_000_000
                time_formatted = format_time(total_seconds)
                cell_content += f'<span class="time-value">{time_formatted}</span>'
                execution_times.append(total_seconds)
            else:
                cell_content += '<span class="no-data">No time data</span>'

            cell_content += '</div>'
            return f'<td>{cell_content}</td>', cycles, total_seconds if 'secs' in duration else None
        else:
            # Test failed or no success data
            error_msg = "Failed"
            if 'failure' in execution:
                error_msg = "Failed"
            elif 'error' in execution:
                error_msg = "Error"
            return f'<td><span class="error-value">{error_msg}</span></td>', None, None
    else:
        # No test result for this combination
        return '<td><span class="no-data">-</span></td>', None, None


def generate_detailed_results(metrics_data: Dict[str, Dict[str, List[MetricsFile]]]) -> str:
    """Generate the detailed test results HTML."""
    html = '''
        <h2 class="section-title">üîç Detailed Test Results</h2>
    '''

    # Get all unique ELs
    all_els = set()
    for zkvm_data in metrics_data.values():
        for el in zkvm_data.keys():
            all_els.add(el)

    for el in sorted(all_els):
        html += generate_el_section(el, metrics_data)

    return html


def generate_el_section(el: str, metrics_data: Dict[str, Dict[str, List[MetricsFile]]]) -> str:
    """Generate HTML for a single EL section."""
    html = f'''
        <div class="el-section">
            <h3 class="el-header" onclick="toggleSection('{el}')" style="cursor: pointer; user-select: none;">
                üìä {el.upper()} <span id="toggle-{el}" class="toggle-indicator">‚ñº</span>
            </h3>
            <div id="section-{el}" class="el-content">
                <div class="overflow-container">
                    <table class="results-table">
                        <thead>
                            <tr>
                                <th class="test-name">Test Name</th>
    '''

    # Create column headers for zkVMs available for this EL
    el_combinations = []
    for zkvm in sorted(metrics_data.keys()):
        if el in metrics_data[zkvm]:
            el_combinations.append(zkvm)
            html += f'<th class="sortable" data-el="{el}" data-col="{len(el_combinations)-1}">{zkvm}<span class="sort-indicator"></span></th>'

    # Add the average cycles column for this EL
    html += f'<th class="sortable" data-el="{el}" data-col="{len(el_combinations)}">Avg. Execution Time<span class="sort-indicator"></span></th>'

    html += '''
                            </tr>
                        </thead>
                        <tbody id="tbody-''' + el + '''">
    '''

    # Collect all unique test names for this EL
    el_test_names = set()
    for zkvm in el_combinations:
        if zkvm in metrics_data and el in metrics_data[zkvm]:
            for test in metrics_data[zkvm][el]:
                test_name = test.name
                clean_name = clean_test_name(test_name)
                el_test_names.add((test_name, clean_name))

    # Sort test names for consistent display
    sorted_el_test_names = sorted(el_test_names, key=lambda x: x[1])

    # Generate table rows for this EL
    for original_name, display_name in sorted_el_test_names:
        html += f'''
                            <tr>
                                <td class="test-name-cell">{display_name}</td>
        '''

        # Collect cycle counts for this test across all zkVMs for this EL
        cycle_counts: List[int] = []
        execution_times: List[float] = []
        row_cells = []

        for zkvm in el_combinations:
            # Find test result for this combination
            test_result = None
            if zkvm in metrics_data and el in metrics_data[zkvm]:
                for test in metrics_data[zkvm][el]:
                    if test.name == original_name:
                        test_result = test
                        break

            cell_html, _, _ = generate_test_cell(test_result, cycle_counts, execution_times)
            row_cells.append(cell_html)

        # Add all the zkVM cells for this EL
        for cell in row_cells:
            html += cell

        # Calculate and add average execution time for this EL
        if execution_times:
            avg_time = sum(execution_times) / len(execution_times)
            avg_time_formatted = format_time(avg_time)
            html += f'<td class="time-value" data-avg-time="{avg_time}">{avg_time_formatted}</td>'
        else:
            html += '<td class="no-data" data-avg-time="-1">No data</td>'

        html += '''
                            </tr>
        '''

    html += '''
                        </tbody>
                    </table>
                </div>
            </div>
        </div>
    '''
    return html


def clean_test_name(test_name: str) -> str:
    """Clean up test name for display using human-readable format."""
    return get_display_name(test_name)


def generate_html_report(metrics_data: Dict[str, Dict[str, List[MetricsFile]]], output_file: Path) -> None:
    """Generate an HTML report from the metrics data."""
    # Build content sections
    content = ''
    if not metrics_data:
        content = '''
        <div class="no-data">
            <h2>No metrics data found</h2>
            <p>No benchmark results were found in the specified directories.</p>
        </div>
        '''
    else:
        content = generate_summary_table(metrics_data) + generate_detailed_results(metrics_data)

    # Generate final HTML
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S UTC")
    html_content = get_html_template().format(
        css_styles=get_css_styles(),
        javascript_code=get_javascript_code(),
        content=content,
        timestamp=timestamp
    )

    # Write the HTML file
    with open(output_file, 'w') as f:
        f.write(html_content)

    print(f"HTML report generated: {output_file}")

def main() -> int:
    """Main entry point for the script."""
    parser = argparse.ArgumentParser(description='Generate zkEVM benchmark website')
    parser.add_argument('--input-dir', '-i', type=Path, default=Path('.'),
                        help='Input directory containing zkevm-metrics folders (default: current directory)')
    parser.add_argument('--output-file', '-o', type=Path, default=Path('index.html'),
                        help='Output HTML file (default: index.html)')

    args = parser.parse_args()

    if not args.input_dir.exists():
        print(f"Error: Input directory {args.input_dir} does not exist")
        return 1

    print(f"Scanning for metrics in: {args.input_dir}")
    metrics_data = collect_metrics_data(args.input_dir)

    if not metrics_data:
        print("Warning: No metrics data found")
    else:
        total_tests = sum(len(el_data) for zkvm_data in metrics_data.values() for el_data in zkvm_data.values())
        print(f"Found {total_tests} test results across {len(metrics_data)} zkVMs")

    generate_html_report(metrics_data, args.output_file)
    return 0

if __name__ == '__main__':
    exit(main())
